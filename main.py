import os
import re
import time
import json
import hashlib
import logging
from typing import Optional

import httpx
from bs4 import BeautifulSoup
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from openai import AsyncOpenAI
from upstash_redis.asyncio import Redis

# --- Ð›Ð¾Ð³Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ ---
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("silvia")

# --- ÐšÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ñ ---
SESSION_TTL_SECONDS = int(os.getenv("SESSION_TTL_SECONDS", "3600"))

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    raise ValueError("Ð¢Ñ€ÐµÐ±ÑƒÐµÑ‚ÑÑ Ð¿ÐµÑ€ÐµÐ¼ÐµÐ½Ð½Ð°Ñ Ð¾ÐºÑ€ÑƒÐ¶ÐµÐ½Ð¸Ñ OPENAI_API_KEY")

UPSTASH_URL = os.getenv("UPSTASH_REDIS_REST_URL")
UPSTASH_TOKEN = os.getenv("UPSTASH_REDIS_REST_TOKEN")
if not UPSTASH_URL or not UPSTASH_TOKEN:
    raise ValueError("Ð¢Ñ€ÐµÐ±ÑƒÑŽÑ‚ÑÑ UPSTASH_REDIS_REST_URL Ð¸ UPSTASH_REDIS_REST_TOKEN")

ALLOWED_ORIGINS = [
    "https://silvia-ai.ru",
    "https://www.silvia-ai.ru",
    "http://localhost:8000",
    "http://localhost:3000",
]

# --- ÐšÐ»Ð¸ÐµÐ½Ñ‚Ñ‹ ---
client = AsyncOpenAI(api_key=OPENAI_API_KEY)
redis = Redis(url=UPSTASH_URL, token=UPSTASH_TOKEN)

# --- ÐœÐ¾Ð´ÐµÐ»Ð¸ ---
class AnalyzeRequest(BaseModel):
    url: str

class AnalyzeResponse(BaseModel):
    session_id: str

class ChatRequest(BaseModel):
    session_id: str
    question: str

class ChatResponse(BaseModel):
    answer: str

# --- Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ FastAPI ---
app = FastAPI(title="Silvia API", version="1.2.0")

app.add_middleware(
    CORSMiddleware,
    allow_origins=ALLOWED_ORIGINS,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- Ð£Ñ‚Ð¸Ð»Ð¸Ñ‚Ñ‹ ---
def normalize_url(url: str) -> str:
    u = url.strip()
    if not re.match(r"^https?://", u, flags=re.I):
        u = "https://" + u  # Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ https
    return u

def is_valid_url(url: str) -> bool:
    try:
        parsed = httpx.URL(url)
        return parsed.scheme in ("http", "https") and bool(parsed.host)
    except Exception:
        return False

def generate_session_id(url: str) -> str:
    return hashlib.sha256(url.encode()).hexdigest()[:16]

def extract_main_content(html: str, url: str):
    soup = BeautifulSoup(html, "lxml")

    # Ð£Ð´Ð°Ð»ÑÐµÐ¼ ÑˆÑƒÐ¼
    for tag in soup(["script", "style", "nav", "footer", "aside", "header", "form", "button", "img", "svg", "noscript"]):
        tag.decompose()

    main = soup.find("main") or soup.find("article") or soup.find("section") or (soup.body if soup else None)
    text = (main or soup).get_text(separator=" ", strip=True) if soup else ""
    text = re.sub(r"\s+", " ", text).strip()

    title = ""
    if soup and soup.title and soup.title.string:
        title = soup.title.string.strip()
    company_name = title or url.split("//")[-1].split("/")[0]

    lang = "ru"
    if soup and soup.html and soup.html.get("lang"):
        lang = soup.html.get("lang").lower()
    lang = lang.split("-")[0]  # en-US -> en

    return {"text": text, "company_name": company_name, "lang": lang}

def smart_truncate(text: str, max_chars: int = 2800) -> str:
    if len(text) <= max_chars:
        return text
    truncated = text[:max_chars]
    last_end = max(
        truncated.rfind(". "),
        truncated.rfind("! "),
        truncated.rfind("? "),
        truncated.rfind(".\n"),
    )
    if last_end != -1:
        return truncated[:last_end + 1]
    return truncated[:max_chars]

# --- Ð­Ð½Ð´Ð¿Ð¾Ð¸Ð½Ñ‚Ñ‹ ---
@app.get("/")
@app.head("/")
async def root():
    return {
        "status": "ok",
        "service": "Silvia API",
        "version": "1.2.0",
        "endpoints": ["/analyze", "/chat", "/health"]
    }

@app.get("/health")
@app.head("/health")
async def health():
    redis_status = "disconnected"
    try:
        pong = await redis.ping()
        redis_status = f"connected: {pong}"
    except Exception as e:
        redis_status = f"error: {e}"

    return {
        "status": "healthy",
        "redis": redis_status,
        "openai": "configured" if OPENAI_API_KEY else "missing",
    }

@app.post("/analyze", response_model=AnalyzeResponse)
async def analyze(req: AnalyzeRequest):
    raw_url = req.url.strip()
    url = normalize_url(raw_url)
    logger.info(f"ðŸ“Š Analyzing URL: {url}")

    if not is_valid_url(url):
        raise HTTPException(status_code=400, detail="Invalid URL")

    session_id = generate_session_id(url)
    session_key = f"sess:{session_id}"

    try:
        headers = {
            "User-Agent": "Mozilla/5.0 SilviaBot/1.0 (+https://silvia-ai.ru)",
            "Accept-Language": "ru,en;q=0.9",
        }
        async with httpx.AsyncClient(timeout=20.0, follow_redirects=True) as http_client:
            try:
                resp = await http_client.get(url, headers=headers)
                resp.raise_for_status()
            except Exception:
                # fallback Ð½Ð° http, ÐµÑÐ»Ð¸ https Ð½Ðµ Ð¾Ñ‚ÐºÑ€Ñ‹Ð»ÑÑ
                if url.startswith("https://"):
                    url_http = "http://" + url[len("https://"):]
                    resp = await http_client.get(url_http, headers=headers)
                    resp.raise_for_status()
                    url = url_http
                else:
                    raise
            html = resp.text

        logger.info(f"âœ… HTML fetched: {len(html)} chars")

        data = extract_main_content(html, url)
        raw_text = data["text"]
        if not raw_text:
            raise HTTPException(status_code=400, detail="No meaningful content found on the site")

        logger.info(f"ðŸ“ Extracted text: {len(raw_text)} chars")

        safe_text = smart_truncate(raw_text, max_chars=2800)
        logger.info(f"âœ‚ï¸ Truncated to: {len(safe_text)} chars")

        session_data = {
            "url": url,
            "company_name": data["company_name"],
            "lang": data["lang"],
            "document": safe_text,
            "created_at": int(time.time()),
        }

        # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ñ TTL
        await redis.set(session_key, json.dumps(session_data), ex=SESSION_TTL_SECONDS)

        logger.info(f"âœ… Session created: {session_id}")
        return AnalyzeResponse(session_id=session_id)

    except httpx.HTTPError as e:
        logger.error(f"âŒ HTTP error: {e}")
        raise HTTPException(status_code=502, detail=f"Failed to fetch URL: {str(e)}")
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ Analysis error: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Analysis error: {str(e)}")

@app.post("/chat", response_model=ChatResponse)
async def chat(req: ChatRequest):
    session_id = (req.session_id or "").strip()
    question = (req.question or "").strip()
    logger.info(f"ðŸ’¬ Chat request: session={session_id}, question={question[:80]}...")

    if not session_id:
        raise HTTPException(status_code=400, detail="Missing session_id")
    if not question:
        raise HTTPException(status_code=400, detail="Question is empty")

    try:
        session_key = f"sess:{session_id}"
        payload_raw = await redis.get(session_key)
        if not payload_raw:
            raise HTTPException(status_code=404, detail="Session not found or expired")

        payload = json.loads(payload_raw)
        document = payload.get("document", "")
        company_name = payload.get("company_name", "Ð²Ð°ÑˆÐµÐ¹ ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ð¸")
        lang = payload.get("lang", "ru")

        # ÐŸÑ€Ð¾ÑÑ‚Ð¾Ðµ Ð¿Ñ€Ð¸Ð²ÐµÑ‚ÑÑ‚Ð²Ð¸Ðµ
        q = question.lower()
        if any(w in q for w in ["Ð¿Ñ€Ð¸Ð²ÐµÑ‚", "Ð·Ð´Ñ€Ð°Ð²", "hi", "hello", "hey"]):
            if lang == "en":
                welcome = f"Hi! I'm the AI assistant for {company_name}. How can I help you today?"
            else:
                welcome = f"Ð—Ð´Ñ€Ð°Ð²ÑÑ‚Ð²ÑƒÐ¹Ñ‚Ðµ! Ð¯ â€” Ñ†Ð¸Ñ„Ñ€Ð¾Ð²Ð¾Ð¹ Ð¿Ð¾Ð¼Ð¾Ñ‰Ð½Ð¸Ðº ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ð¸ {company_name}. Ð§ÐµÐ¼ Ð¼Ð¾Ð³Ñƒ Ð¿Ð¾Ð¼Ð¾Ñ‡ÑŒ?"
            return ChatResponse(answer=welcome)

        system_prompt = f"""Ð’Ñ‹ â€” Silvia, Ð¸Ð½Ñ‚ÐµÐ»Ð»ÐµÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ñ‹Ð¹ Ñ†Ð¸Ñ„Ñ€Ð¾Ð²Ð¾Ð¹ ÑÐ¾Ñ‚Ñ€ÑƒÐ´Ð½Ð¸Ðº ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ð¸ Â«{company_name}Â».
ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹Ñ‚Ðµ Ð¢ÐžÐ›Ð¬ÐšÐž Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ Ñ Ð³Ð»Ð°Ð²Ð½Ð¾Ð¹ ÑÑ‚Ñ€Ð°Ð½Ð¸Ñ†Ñ‹ ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ð¸.

ÐŸÑ€Ð°Ð²Ð¸Ð»Ð°:
1) Ð¢Ð¾Ð½: Ð´Ñ€ÑƒÐ¶ÐµÐ»ÑŽÐ±Ð½Ð¾ Ð¸ Ð¿Ñ€Ð¾Ñ„ÐµÑÑÐ¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾.
2) ÐÐµ Ð²Ñ‹Ð´ÑƒÐ¼Ñ‹Ð²Ð°Ð¹Ñ‚Ðµ Ñ„Ð°ÐºÑ‚Ð¾Ð². Ð•ÑÐ»Ð¸ Ð´Ð°Ð½Ð½Ñ‹Ñ… Ð½ÐµÑ‚ â€” ÑÐºÐ°Ð¶Ð¸Ñ‚Ðµ: Â«Ð­Ñ‚Ð¾Ð³Ð¾ Ð½ÐµÑ‚ Ð½Ð° ÑÐ°Ð¹Ñ‚Ðµ, Ð½Ð¾ Ñ Ð¼Ð¾Ð³Ñƒ ÑƒÑ‚Ð¾Ñ‡Ð½Ð¸Ñ‚ÑŒ Ñƒ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹!Â».
3) ÐÐµ Ð³Ð¾Ð²Ð¾Ñ€Ð¸Ñ‚Ðµ Â«ÐÐ° ÑÐ°Ð¹Ñ‚Ðµ Ð½Ð°Ð¿Ð¸ÑÐ°Ð½Ð¾â€¦Â». Ð’Ñ‹ â€” Ð³Ð¾Ð»Ð¾Ñ ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ð¸.
4) ÐžÑ‚Ð²ÐµÑ‚Ñ‹ ÐºÑ€Ð°Ñ‚ÐºÐ¸Ðµ (1â€“3 Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ), Ð½Ð¾ Ð¿Ð¾Ð»ÐµÐ·Ð½Ñ‹Ðµ.
5) Ð’Ð¾Ð¿Ñ€Ð¾ÑÑ‹ Ð½Ðµ Ð¿Ð¾ Ñ‚ÐµÐ¼Ðµ â€” Ð¼ÑÐ³ÐºÐ¾ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°Ð¹Ñ‚Ðµ Ðº Ñ‚ÐµÐ¼Ð°Ñ‚Ð¸ÐºÐµ ÐºÐ¾Ð¼Ð¿Ð°Ð½Ð¸Ð¸.

ÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ (Ð½Ðµ Ñ†Ð¸Ñ‚Ð¸Ñ€ÑƒÐ¹Ñ‚Ðµ Ð´Ð¾ÑÐ»Ð¾Ð²Ð½Ð¾):
{document}
"""

        chat_resp = await client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": question},
            ],
            temperature=0.75,
            max_tokens=300,
            top_p=0.9,
        )

        answer = chat_resp.choices[0].message.content.strip() if chat_resp.choices else "Ð˜Ð·Ð²Ð¸Ð½Ð¸Ñ‚Ðµ, Ð½Ðµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ ÑÐ³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð¾Ñ‚Ð²ÐµÑ‚."
        logger.info(f"âœ… Answer generated: {len(answer)} chars")
        return ChatResponse(answer=answer)

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ Chat error: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Generation error: {str(e)}")
