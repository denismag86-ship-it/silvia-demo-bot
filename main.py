from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
import httpx
from bs4 import BeautifulSoup
import re
import time
import hashlib
import os
import logging
from pydantic import BaseModel
from openai import AsyncOpenAI
import chromadb
from chromadb.config import Settings

# --- –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ ---
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# --- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ---
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    raise ValueError("–¢—Ä–µ–±—É–µ—Ç—Å—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è OPENAI_API_KEY")

COLLECTION_NAME = "demo_sites"
SESSION_TTL_SECONDS = 3600

# --- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è FastAPI ---
app = FastAPI(title="Silvia API", version="1.0.0")

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "https://silvia-ai.ru",
        "https://www.silvia-ai.ru",
        "http://localhost:8000",
        "http://localhost:3000",
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

client = AsyncOpenAI(api_key=OPENAI_API_KEY)

# üî• ChromaDB ‚Äî –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ó–∞—â–∏—Ç–∞ –æ—Ç –ø–æ—Ç–µ—Ä–∏ –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–µ
try:
    chroma_client = chromadb.Client(Settings(
        anonymized_telemetry=False,
        allow_reset=True,
    ))
    logger.info("‚úÖ ChromaDB initialized (in-memory mode)")
except Exception as e:
    logger.error(f"‚ùå ChromaDB initialization failed: {e}")
    chroma_client = None

# --- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ---
def get_collection():
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
    if not chroma_client:
        raise HTTPException(status_code=503, detail="ChromaDB not available")
    
    try:
        return chroma_client.get_or_create_collection(name=COLLECTION_NAME)
    except Exception as e:
        logger.error(f"‚ùå Collection error: {e}")
        # –ü—ã—Ç–∞–µ–º—Å—è –ø–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å –∫–æ–ª–ª–µ–∫—Ü–∏—é –ø—Ä–∏ –æ—à–∏–±–∫–µ
        try:
            chroma_client.delete_collection(name=COLLECTION_NAME)
        except:
            pass
        return chroma_client.create_collection(name=COLLECTION_NAME)

def is_valid_url(url: str) -> bool:
    try:
        result = httpx.URL(url)
        return result.scheme in ("http", "https") and bool(result.host)
    except Exception:
        return False

def generate_session_id(url: str) -> str:
    return hashlib.sha256(url.encode()).hexdigest()[:16]

def extract_main_content(html: str, url: str):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–æ–ª—å–∫–æ –æ—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ç–µ–Ω—Ç —Å–∞–π—Ç–∞, —É–¥–∞–ª—è—è —à—É–º."""
    soup = BeautifulSoup(html, "lxml")
    
    for tag in soup(["script", "style", "nav", "footer", "aside", "header", "form", "button", "img", "svg", "noscript"]):
        tag.decompose()
    
    main = soup.find("main") or soup.find("article") or soup.find("section") or soup.body
    if main:
        text = main.get_text(separator=" ", strip=True)
    else:
        text = soup.get_text(separator=" ", strip=True)
    
    text = re.sub(r"\s+", " ", text).strip()
    
    title = soup.title.string if soup.title else ""
    company_name = title or url.split("//")[-1].split("/")[0]
    lang = soup.html.get("lang", "ru") if soup.html else "ru"
    
    return {"text": text, "company_name": company_name, "lang": lang}

def smart_truncate(text: str, max_chars: int = 2800) -> str:
    """–û–±—Ä–µ–∑–∞–µ—Ç —Ç–µ–∫—Å—Ç –¥–æ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –ø–æ–ª–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è."""
    if len(text) <= max_chars:
        return text
    truncated = text[:max_chars]
    last_end = max(
        truncated.rfind(". "),
        truncated.rfind("! "),
        truncated.rfind("? "),
        truncated.rfind(".\n"),
    )
    if last_end != -1:
        return truncated[:last_end + 1]
    return truncated[:max_chars]

# --- –≠–Ω–¥–ø–æ–∏–Ω—Ç—ã ---
@app.get("/")
@app.head("/")
async def root():
    """Health check endpoint"""
    return {
        "status": "ok",
        "service": "Silvia API",
        "version": "1.0.0",
        "endpoints": ["/analyze", "/chat", "/health"]
    }

@app.get("/health")
@app.head("/health")
async def health():
    """Detailed health check"""
    chroma_status = "connected" if chroma_client else "disconnected"
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∫–æ–ª–ª–µ–∫—Ü–∏—è –¥–æ—Å—Ç—É–ø–Ω–∞
    try:
        if chroma_client:
            collection = get_collection()
            chroma_status = f"connected, collection: {collection.count()}"
    except Exception as e:
        chroma_status = f"error: {str(e)}"
    
    return {
        "status": "healthy",
        "chromadb": chroma_status,
        "openai": "configured" if OPENAI_API_KEY else "missing"
    }

@app.post("/analyze", response_model=AnalyzeResponse)
async def analyze(req: AnalyzeRequest):
    url = req.url.strip()
    logger.info(f"üìä Analyzing URL: {url}")
    
    if not is_valid_url(url):
        raise HTTPException(status_code=400, detail="Invalid URL")
    
    session_id = generate_session_id(url)
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º HTML
        async with httpx.AsyncClient(timeout=10.0, follow_redirects=True) as http_client:
            resp = await http_client.get(url)
            resp.raise_for_status()
            html = resp.text
        
        logger.info(f"‚úÖ HTML fetched: {len(html)} chars")
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç
        data = extract_main_content(html, url)
        raw_text = data["text"]
        
        if not raw_text:
            raise HTTPException(status_code=400, detail="No meaningful content found on the site")
        
        logger.info(f"üìù Extracted text: {len(raw_text)} chars")
        
        # –û–±—Ä–µ–∑–∞–µ–º –¥–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
        safe_text = smart_truncate(raw_text, max_chars=2800)
        logger.info(f"‚úÇÔ∏è Truncated to: {len(safe_text)} chars")
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥
        embedding_resp = await client.embeddings.create(
            input=safe_text, 
            model="text-embedding-3-small"
        )
        embedding = embedding_resp.data[0].embedding
        logger.info(f"üß† Embedding created: {len(embedding)} dimensions")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ ChromaDB
        collection = get_collection()
        collection.upsert(
            ids=[session_id],
            embeddings=[embedding],
            documents=[safe_text],
            metadatas=[{
                "url": url,
                "company_name": data["company_name"],
                "lang": data["lang"],
                "created_at": int(time.time())
            }]
        )
        
        logger.info(f"‚úÖ Session created: {session_id}")
        return AnalyzeResponse(session_id=session_id)
    
    except httpx.HTTPError as e:
        logger.error(f"‚ùå HTTP error: {e}")
        raise HTTPException(status_code=502, detail=f"Failed to fetch URL: {str(e)}")
    except Exception as e:
        logger.error(f"‚ùå Analysis error: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Analysis error: {str(e)}")

@app.post("/chat", response_model=ChatResponse)
async def chat(req: ChatRequest):
    session_id = req.session_id
    question = req.question.strip()
    
    logger.info(f"üí¨ Chat request: session={session_id}, question={question[:50]}...")
    
    if not question:
        raise HTTPException(status_code=400, detail="Question is empty")
    
    try:
        collection = get_collection()
        results = collection.get(ids=[session_id])
        
        if not results["ids"]:
            raise HTTPException(status_code=404, detail="Session not found")
        
        created_at = results["metadatas"][0]["created_at"]
        if time.time() - created_at > SESSION_TTL_SECONDS:
            collection.delete(ids=[session_id])
            raise HTTPException(status_code=410, detail="Session expired")
        
        document = results["documents"][0]
        company_name = results["metadatas"][0]["company_name"]
        lang = results["metadatas"][0]["lang"]

        # –ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ
        if lang == "en":
            welcome = f"Hi! I'm the AI assistant for {company_name}. How can I help you today?"
        else:
            welcome = f"–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ! –Ø ‚Äî —Ü–∏—Ñ—Ä–æ–≤–æ–π –ø–æ–º–æ—â–Ω–∏–∫ –∫–æ–º–ø–∞–Ω–∏–∏ {company_name}. –ß–µ–º –º–æ–≥—É –ø–æ–º–æ—á—å?"

        if len(question) < 5 and any(w in question.lower() for w in ["–ø—Ä–∏–≤", "hi", "hello", "–∑–¥—Ä–∞–≤"]):
            return ChatResponse(answer=welcome)

        # –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º—Ç
        system_prompt = f"""–í—ã ‚Äî Silvia, –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π —Ü–∏—Ñ—Ä–æ–≤–æ–π —Å–æ—Ç—Ä—É–¥–Ω–∏–∫ –∫–æ–º–ø–∞–Ω–∏–∏ ¬´{company_name}¬ª. 
–í–∞—à–∞ –∑–∞–¥–∞—á–∞ ‚Äî –æ—Ç–≤–µ—á–∞—Ç—å –æ—Ç –ª–∏—Ü–∞ –∫–æ–º–ø–∞–Ω–∏–∏, –∏—Å–ø–æ–ª—å–∑—É—è –¢–û–õ–¨–ö–û –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é —Å –µ—ë –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã.

–ü—Ä–∞–≤–∏–ª–∞:
1. –ì–æ–≤–æ—Ä–∏—Ç–µ –¥—Ä—É–∂–µ–ª—é–±–Ω–æ, –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ –∏ —Å –ª—ë–≥–∫–æ–π –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å—é.
2. –ù–ï –≤—ã–¥—É–º—ã–≤–∞–π—Ç–µ —Ñ–∞–∫—Ç—ã. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ—Ç ‚Äî —Å–∫–∞–∂–∏—Ç–µ: ¬´–≠—Ç–æ –Ω–µ —É–∫–∞–∑–∞–Ω–æ –Ω–∞ —Å–∞–π—Ç–µ, –Ω–æ —è –º–æ–≥—É —É—Ç–æ—á–Ω–∏—Ç—å —É –∫–æ–º–∞–Ω–¥—ã!¬ª
3. –ò–∑–±–µ–≥–∞–π—Ç–µ —Ñ—Ä–∞–∑ –≤—Ä–æ–¥–µ ¬´–ù–∞ —Å–∞–π—Ç–µ –Ω–∞–ø–∏—Å–∞–Ω–æ‚Ä¶¬ª. –í—ã ‚Äî –≥–æ–ª–æ—Å –∫–æ–º–ø–∞–Ω–∏–∏.
4. –û—Ç–≤–µ—Ç—ã ‚Äî –∫—Ä–∞—Ç–∫–∏–µ (1‚Äì3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è), –Ω–æ –ø–æ–ª–µ–∑–Ω—ã–µ.
5. –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –Ω–µ –ø–æ —Ç–µ–º–µ ‚Äî –º—è–≥–∫–æ –≤–µ—Ä–Ω–∏—Ç–µ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç.

–ö–æ–Ω—Ç–µ–∫—Å—Ç (–Ω–µ —Ü–∏—Ç–∏—Ä—É–π—Ç–µ –¥–æ—Å–ª–æ–≤–Ω–æ):
{document}
"""

        chat_resp = await client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": question}
            ],
            temperature=0.75,
            max_tokens=300,
            top_p=0.9
        )
        answer = chat_resp.choices[0].message.content.strip()
        logger.info(f"‚úÖ Answer generated: {len(answer)} chars")
        return ChatResponse(answer=answer)
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Chat error: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Generation error: {str(e)}")

# –ú–æ–¥–µ–ª–∏ –æ—Å—Ç–∞—é—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
class AnalyzeRequest(BaseModel):
    url: str

class AnalyzeResponse(BaseModel):
    session_id: str

class ChatRequest(BaseModel):
    session_id: str
    question: str

class ChatResponse(BaseModel):
    answer: str
