# –ü–æ–ª–Ω–æ–µ –æ—Ç–∫–ª—é—á–µ–Ω–∏–µ —Ç–µ–ª–µ–º–µ—Ç—Ä–∏–∏ chromadb —á–µ—Ä–µ–∑ monkey patching
import os
os.environ["CHROMA_TELEMETRY"] = "false"
os.environ["ANONYMIZED_TELEMETRY"] = "false"
os.environ["CHROMA_DISABLE_OPENTELEMETRY"] = "true"
os.environ["CHROMA_DISABLE_EVENTS"] = "true"

# –ò–º–ø–æ—Ä—Ç—ã
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
import httpx
from bs4 import BeautifulSoup
import re
import time
import logging
import hashlib
from pydantic import BaseModel
from openai import AsyncOpenAI
import chromadb
from chromadb.config import Settings

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("main")

# --- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ---
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    raise ValueError("–¢—Ä–µ–±—É–µ—Ç—Å—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è OPENAI_API_KEY")

COLLECTION_NAME = "demo_sites"
SESSION_TTL_SECONDS = 3600

# --- –ü–æ–ª–Ω–æ–µ –æ—Ç–∫–ª—é—á–µ–Ω–∏–µ —Ç–µ–ª–µ–º–µ—Ç—Ä–∏–∏ chromadb ---
# Monkey patching –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –æ—Ç–∫–ª—é—á–µ–Ω–∏—è —Ç–µ–ª–µ–º–µ—Ç—Ä–∏–∏
def mock_capture(*args, **kwargs):
    return None

try:
    # –ü–∞—Ç—á–∏–º PostHog –∫–ª–∏–µ–Ω—Ç –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –æ—Ç–∫–ª—é—á–µ–Ω–∏—è —Ç–µ–ª–µ–º–µ—Ç—Ä–∏–∏
    import chromadb.telemetry.product.posthog
    chromadb.telemetry.product.posthog.Posthog = type('MockPosthog', (), {
        'capture': staticmethod(mock_capture),
        '_capture': staticmethod(mock_capture),
        '__init__': lambda *args, **kwargs: None
    })
except Exception as e:
    logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ—Ç–∫–ª—é—á–∏—Ç—å —Ç–µ–ª–µ–º–µ—Ç—Ä–∏—é: {str(e)}")

# --- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è FastAPI ---
app = FastAPI()

# üî• CORS ‚Äî –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: —É–±—Ä–∞–Ω—ã –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –≤ URL
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "https://silvia-ai.ru",
        "https://www.silvia-ai.ru",
        "http://localhost:8000",
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

client = AsyncOpenAI(api_key=OPENAI_API_KEY)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ChromaDB —Å –ø–æ–ª–Ω—ã–º –æ—Ç–∫–ª—é—á–µ–Ω–∏–µ–º —Ç–µ–ª–µ–º–µ—Ç—Ä–∏–∏
chroma_client = chromadb.Client(Settings(
    anonymized_telemetry=False,
    allow_reset=False,
    is_persistent=False
))

# --- –ú–æ–¥–µ–ª–∏ ---
class AnalyzeRequest(BaseModel):
    url: str

class AnalyzeResponse(BaseModel):
    session_id: str

class ChatRequest(BaseModel):
    session_id: str
    question: str

class ChatResponse(BaseModel):
    answer: str

# --- –ö—ç—à –∫–æ–ª–ª–µ–∫—Ü–∏–∏ ---
_collection_cache = None

def get_collection():
    global _collection_cache
    if _collection_cache is None:
        try:
            logger.info(f"üîç –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–ª–µ–∫—Ü–∏—é: {COLLECTION_NAME}")
            _collection_cache = chroma_client.get_collection(name=COLLECTION_NAME)
        except:
            logger.info(f"üÜï –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –∫–æ–ª–ª–µ–∫—Ü–∏—é: {COLLECTION_NAME}")
            _collection_cache = chroma_client.create_collection(
                name=COLLECTION_NAME,
                metadata={"hnsw:space": "cosine"}
            )
    return _collection_cache

# --- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ---
def is_valid_url(url: str) -> bool:
    try:
        result = httpx.URL(url)
        return result.scheme in ("http", "https") and bool(result.host)
    except Exception:
        return False

def generate_session_id(url: str) -> str:
    return hashlib.sha256(url.encode()).hexdigest()[:16]

def extract_main_content(html: str, url: str):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–æ–ª—å–∫–æ –æ—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ç–µ–Ω—Ç —Å–∞–π—Ç–∞, —É–¥–∞–ª—è—è —à—É–º."""
    logger.info("üßπ –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞...")
    soup = BeautifulSoup(html, "lxml")
    
    # –£–¥–∞–ª—è–µ–º –≤—Å—ë –ª–∏—à–Ω–µ–µ
    for tag in soup(["script", "style", "nav", "footer", "aside", "header", "form", "button", "img", "svg", "noscript"]):
        tag.decompose()
    
    # –ò—â–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ç–µ–Ω—Ç
    main = soup.find("main") or soup.find("article") or soup.find("section") or soup.body
    if main:
        text = main.get_text(separator=" ", strip=True)
    else:
        text = soup.get_text(separator=" ", strip=True)
    
    # –û—á–∏—â–∞–µ–º –ø—Ä–æ–±–µ–ª—ã
    text = re.sub(r"\s+", " ", text).strip()
    
    # –ü–æ–ª—É—á–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∫–æ–º–ø–∞–Ω–∏–∏
    title = soup.title.string if soup.title else ""
    company_name = title or url.split("//")[-1].split("/")[0]
    lang = soup.html.get("lang", "ru") if soup.html else "ru"
    
    logger.info(f"üìù –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
    return {"text": text, "company_name": company_name, "lang": lang}

def smart_truncate(text: str, max_chars: int = 2800) -> str:
    """–û–±—Ä–µ–∑–∞–µ—Ç —Ç–µ–∫—Å—Ç –¥–æ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –ø–æ–ª–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è."""
    if len(text) <= max_chars:
        return text
    truncated = text[:max_chars]
    last_end = max(
        truncated.rfind(". "),
        truncated.rfind("! "),
        truncated.rfind("? "),
        truncated.rfind(".\n"),
    )
    if last_end != -1:
        return truncated[:last_end + 1]
    return truncated[:max_chars]  # fallback

# --- –≠–Ω–¥–ø–æ–∏–Ω—Ç—ã ---
@app.post("/analyze", response_model=AnalyzeResponse)
async def analyze(req: AnalyzeRequest):
    url = req.url.strip()
    logger.info(f"üìä –ê–Ω–∞–ª–∏–∑ URL: {url}")
    
    if not is_valid_url(url):
        logger.warning(f"URLException: –ù–µ–≤–µ—Ä–Ω—ã–π URL - {url}")
        raise HTTPException(status_code=400, detail="Invalid URL")
    
    session_id = generate_session_id(url)
    logger.info(f"üÜî –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω session_id: {session_id}")
    
    try:
        async with httpx.AsyncClient(timeout=10.0, follow_redirects=True) as http_client:
            logger.info(f"üåê –ó–∞–ø—Ä–æ—Å –∫ {url}")
            resp = await http_client.get(url)
            resp.raise_for_status()
            html = resp.text
            logger.info(f"‚úÖ HTML –∑–∞–≥—Ä—É–∂–µ–Ω: {len(html)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        data = extract_main_content(html, url)
        raw_text = data["text"]
        
        if not raw_text or len(raw_text) < 50:
            logger.warning(f"_ContentWarning: –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –Ω–∞ —Å–∞–π—Ç–µ {url}")
            raise HTTPException(status_code=400, detail="No meaningful content found on the site")
        
        # –û–±—Ä–µ–∑–∞–µ–º –¥–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
        safe_text = smart_truncate(raw_text, max_chars=2800)
        logger.info(f"‚úÇÔ∏è –¢–µ–∫—Å—Ç –æ–±—Ä–µ–∑–∞–Ω –¥–æ: {len(safe_text)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥
        logger.info("üß† –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞...")
        embedding_resp = await client.embeddings.create(input=safe_text, model="text-embedding-3-small")
        embedding = embedding_resp.data[0].embedding
        logger.info(f"‚úÖ –≠–º–±–µ–¥–¥–∏–Ω–≥ —Å–æ–∑–¥–∞–Ω: {len(embedding)} –∏–∑–º–µ—Ä–µ–Ω–∏–π")
        
        # –†–∞–±–æ—Ç–∞ —Å –∫–æ–ª–ª–µ–∫—Ü–∏–µ–π
        collection = get_collection()
        logger.info("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –∫–æ–ª–ª–µ–∫—Ü–∏—é...")
        
        collection.upsert(
            ids=[session_id],
            embeddings=[embedding],
            documents=[safe_text],
            metadatas=[{
                "url": url,
                "company_name": data["company_name"],
                "lang": data["lang"],
                "created_at": int(time.time())
            }]
        )
        logger.info(f"‚úÖ –°–µ—Å—Å–∏—è —Å–æ–∑–¥–∞–Ω–∞: {session_id}")
        return AnalyzeResponse(session_id=session_id)
    
    except Exception as e:
        error_detail = str(e)
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ: {error_detail}")
        
        # –°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ —Å–µ—Ç–∏
        if "timeout" in error_detail.lower() or "connect" in error_detail.lower():
            error_detail = "–°–∞–π—Ç –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç –∏–ª–∏ —Å–ª–∏—à–∫–æ–º –º–µ–¥–ª–µ–Ω–Ω–æ –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."
        elif "status code 4" in error_detail.lower() or "status code 5" in error_detail.lower():
            error_detail = "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–æ—Å—Ç—É–ø –∫ —Å–∞–π—Ç—É. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Å–∞–π—Ç –¥–æ—Å—Ç—É–ø–µ–Ω –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞."
        
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Å–∞–π—Ç–∞: {error_detail}")

@app.post("/chat", response_model=ChatResponse)
async def chat(req: ChatRequest):
    session_id = req.session_id
    question = req.question.strip()
    logger.info(f"üí¨ –ß–∞—Ç-–∑–∞–ø—Ä–æ—Å –¥–ª—è —Å–µ—Å—Å–∏–∏ {session_id}: '{question[:50]}...'")
    
    if not question:
        logger.warning("‚ö†Ô∏è –ü—É—Å—Ç–æ–π –≤–æ–ø—Ä–æ—Å")
        raise HTTPException(status_code=400, detail="Question is empty")
    
    try:
        collection = get_collection()
        results = collection.get(ids=[session_id], include=["documents", "metadatas"])
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ –∫–æ–ª–ª–µ–∫—Ü–∏–∏: {str(e)}")
        raise HTTPException(status_code=500, detail="–û—à–∏–±–∫–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö")
    
    if not results["ids"]:
        logger.warning(f"‚ö†Ô∏è –°–µ—Å—Å–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {session_id}")
        raise HTTPException(status_code=404, detail="Session not found")
    
    created_at = results["metadatas"][0]["created_at"]
    if time.time() - created_at > SESSION_TTL_SECONDS:
        collection.delete(ids=[session_id])
        logger.info(f"üßπ –£–¥–∞–ª–µ–Ω–∞ —É—Å—Ç–∞—Ä–µ–≤—à–∞—è —Å–µ—Å—Å–∏—è: {session_id}")
        raise HTTPException(status_code=410, detail="Session expired")
    
    document = results["documents"][0]
    company_name = results["metadatas"][0]["company_name"]
    lang = results["metadatas"][0]["lang"]
    logger.info(f"üè¢ –ö–æ–º–ø–∞–Ω–∏—è: {company_name}, –Ø–∑—ã–∫: {lang}")

    # –ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ
    if lang == "en":
        welcome = f"Hi! I'm the AI assistant for {company_name}. How can I help you today?"
    else:
        welcome = f"–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ! –Ø ‚Äî —Ü–∏—Ñ—Ä–æ–≤–æ–π –ø–æ–º–æ—â–Ω–∏–∫ –∫–æ–º–ø–∞–Ω–∏–∏ {company_name}. –ß–µ–º –º–æ–≥—É –ø–æ–º–æ—á—å?"

    if len(question) < 5 and any(w in question.lower() for w in ["–ø—Ä–∏–≤", "hi", "hello", "–∑–¥—Ä–∞–≤", "–∑–¥–∞—Ä", "–ø—Ä–∏–≤–µ—Ç", "–∫—É"]):
        logger.info("üëã –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ")
        return ChatResponse(answer=welcome)

    # –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º—Ç
    system_prompt = f"""–í—ã ‚Äî Silvia, –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π —Ü–∏—Ñ—Ä–æ–≤–æ–π —Å–æ—Ç—Ä—É–¥–Ω–∏–∫ –∫–æ–º–ø–∞–Ω–∏–∏ ¬´{company_name}¬ª. 
–í–∞—à–∞ –∑–∞–¥–∞—á–∞ ‚Äî –æ—Ç–≤–µ—á–∞—Ç—å –æ—Ç –ª–∏—Ü–∞ –∫–æ–º–ø–∞–Ω–∏–∏, –∏—Å–ø–æ–ª—å–∑—É—è –¢–û–õ–¨–ö–û –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é —Å –µ—ë –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã.

–ü—Ä–∞–≤–∏–ª–∞:
1. –ì–æ–≤–æ—Ä–∏—Ç–µ –¥—Ä—É–∂–µ–ª—é–±–Ω–æ, –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ –∏ —Å –ª—ë–≥–∫–æ–π –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å—é.
2. –ù–ï –≤—ã–¥—É–º—ã–≤–∞–π—Ç–µ —Ñ–∞–∫—Ç—ã. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ—Ç ‚Äî —Å–∫–∞–∂–∏—Ç–µ: ¬´–≠—Ç–æ –Ω–µ —É–∫–∞–∑–∞–Ω–æ –Ω–∞ —Å–∞–π—Ç–µ, –Ω–æ —è –º–æ–≥—É —É—Ç–æ—á–Ω–∏—Ç—å —É –∫–æ–º–∞–Ω–¥—ã!¬ª
3. –ò–∑–±–µ–≥–∞–π—Ç–µ —Ñ—Ä–∞–∑ –≤—Ä–æ–¥–µ ¬´–ù–∞ —Å–∞–π—Ç–µ –Ω–∞–ø–∏—Å–∞–Ω–æ‚Ä¶¬ª. –í—ã ‚Äî –≥–æ–ª–æ—Å –∫–æ–º–ø–∞–Ω–∏–∏.
4. –û—Ç–≤–µ—Ç—ã ‚Äî –∫—Ä–∞—Ç–∫–∏–µ (1‚Äì3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è), –Ω–æ –ø–æ–ª–µ–∑–Ω—ã–µ.
5. –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –Ω–µ –ø–æ —Ç–µ–º–µ ‚Äî –º—è–≥–∫–æ –≤–µ—Ä–Ω–∏—Ç–µ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç.

–ö–æ–Ω—Ç–µ–∫—Å—Ç (–Ω–µ —Ü–∏—Ç–∏—Ä—É–π—Ç–µ –¥–æ—Å–ª–æ–≤–Ω–æ):
{document}
"""

    try:
        logger.info("ü§ñ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞...")
        chat_resp = await client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": question}
            ],
            temperature=0.75,
            max_tokens=300,
            top_p=0.9
        )
        answer = chat_resp.choices[0].message.content.strip()
        logger.info(f"‚úÖ –û—Ç–≤–µ—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω: '{answer[:50]}...'")
        return ChatResponse(answer=answer)
    except Exception as e:
        error_detail = str(e)
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {error_detail}")
        
        if "APIConnectionError" in error_detail:
            error_detail = "–°–µ—Ä–≤–∏—Å –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."
        elif "AuthenticationError" in error_detail:
            error_detail = "–û—à–∏–±–∫–∞ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å–µ—Ä–≤–∏—Å–∞. –û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É."
        
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {error_detail}")

# --- Health check endpoint ---
@app.get("/health")
async def health_check():
    logger.info("‚ù§Ô∏è Health check –∑–∞–ø—Ä–æ—à–µ–Ω")
    chroma_status = "ok"
    try:
        collection = get_collection()
        chroma_status = f"ok (count: {collection.count()})"
    except Exception as e:
        chroma_status = f"error: {str(e)}"
    
    return {
        "status": "ok", 
        "service": "silvia-ai-demo",
        "chroma_db": chroma_status,
        "openai_api_key_present": bool(OPENAI_API_KEY),
        "timestamp": int(time.time())
    }

@app.get("/")
async def root():
    return {"message": "Silvia AI Demo API", "version": "1.0"}

